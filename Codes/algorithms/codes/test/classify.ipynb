{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (161, 27) (161,) Test (70, 27) (70,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL RESULTS: \n",
      "LogisticRegression: 14.286\n",
      "DecisionTreeClassifier: 21.429\n",
      "GaussianNB: 11.429\n",
      "KNeighborsClassifier: 14.286\n",
      "ExtraTreesClassifier: 34.286\n",
      "RandomForestClassifier: 34.286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "class Classify:\n",
    "\n",
    "    # Initializer / Instance Attributes\n",
    "    def __init__(self, k):\n",
    "        self.models = list()\n",
    "        # define split of data\n",
    "        self.k = k\n",
    "\n",
    "\n",
    "    # create a list of base-models\n",
    "    def get_models(self):\n",
    "        self.models.append(LogisticRegression(solver='liblinear'))\n",
    "        self.models.append(DecisionTreeClassifier())\n",
    "        self.models.append(GaussianNB())\n",
    "        self.models.append(KNeighborsClassifier())\n",
    "        self.models.append(ExtraTreesClassifier(n_estimators=10))\n",
    "        self.models.append(RandomForestClassifier(n_estimators=500, verbose=1, n_jobs=-1))\n",
    "        # self.models.append(SVC(gamma='scale', probability=True))\n",
    "        # self.models.append(AdaBoostClassifier())\n",
    "        # self.models.append(BaggingClassifier(n_estimators=10))\n",
    "\n",
    "    def create_dataset(self):\n",
    "        sys.path.append(os.getcwd()+'\\\\test_data\\\\resultDF_lastFilter.csv')  \n",
    "        path = sys.path[-1]\n",
    "        dataset = pd.read_csv(path, sep=',', header=0)\n",
    "        \n",
    "        # X, y = make_blobs(n_samples=1000, centers=3, n_features=2, random_state=0)\n",
    "        \n",
    "        X = dataset.iloc[:, 2:-1].values\n",
    "        y = dataset.iloc[:, 0]\n",
    "        y = y.astype('string')\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    # collect out of fold predictions form k-fold cross validation\n",
    "    def get_out_of_fold_predictions(self, X, y):\n",
    "        kfold = KFold(n_splits = self.k, shuffle=True)\n",
    "        # enumerate splits\n",
    "        for train_ix, test_ix in kfold.split(X):\n",
    "            fold_yhats = list()\n",
    "            # get data\n",
    "            train_X, test_X = X[train_ix], X[test_ix]\n",
    "            train_y, test_y = y[train_ix], y[test_ix]\n",
    "           \n",
    "            # fit and make predictions with each sub-model\n",
    "            for model in self.models:\n",
    "                model.fit(train_X, train_y)\n",
    "                yhat = model.predict_proba(test_X)\n",
    "                # store columns\n",
    "                fold_yhats.append(yhat)\n",
    "\n",
    "\n",
    "\n",
    "    # evaluate a list of models on a dataset\n",
    "    def evaluate_models(self, X, y):\n",
    "        result = list()\n",
    "        for model in self.models:\n",
    "            yhat = model.predict(X)\n",
    "            acc = accuracy_score(y, yhat)\n",
    "            result.append('%s: %.3f' % (model.__class__.__name__, acc*100))\n",
    "        return result\n",
    "\n",
    "\n",
    "    def main(self):\n",
    "        # create the inputs and outputs\n",
    "        X, y = self.create_dataset() \n",
    "\n",
    "        # split\n",
    "        X, X_val, y, y_val = train_test_split(X, y, test_size=0.30)\n",
    "        y = y.to_numpy()\n",
    "        print('Train', X.shape, y.shape, 'Test', X_val.shape, y_val.shape)\n",
    "\n",
    "        # get models\n",
    "        self.get_models()\n",
    "\n",
    "        # get out of fold predictions\n",
    "        self.get_out_of_fold_predictions(X, y)\n",
    "    \n",
    "\n",
    "        # evaluate base models\n",
    "        result = self.evaluate_models(X_val, y_val)\n",
    "        print(\"MODEL RESULTS: \")\n",
    "        for item in result:\n",
    "            print(item)\n",
    "\n",
    "mn = Classify(3)\n",
    "mn.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
